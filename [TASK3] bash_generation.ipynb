{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10264294,"sourceType":"datasetVersion","datasetId":6349958}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Практическое задание 3\n# Генерация bash команды по текстовому запросу\n## курс \"Математические методы анализа текстов\"\n### ФИО:","metadata":{"id":"HUL0HkgCgcbj"}},{"cell_type":"markdown","source":"### Постановка задачи\n\nВ этом задании вы построите систему, выдающую пользователю последовательность утилит командной строки linux (с нужными флагами) по его текстовому запросу. Вам дан набор пар текстовый запрос - команда на выходе.\n\nРешение этого задания будет построено на encoder-decoder архитектуре и модели transformer.\n\n\n### Библиотеки\n\nДля этого задания вам понадобятся следующие библиотеки:\n* pytorch\n* transformers\n* sentencepiece (bpe токенизация)\n* clai utils (скачать с гитхаба отсюда https://github.com/IBM/clai/tree/nlc2cmd/utils)\n\n\n### Данные\n\nВ качестве обучающей выборке используются данные, сгенерированные автоматически по запросам с сайта stack overflow. В качестве тестовых данных используются пары запросов, размеченные асессорами.\n\nДанные можно скачать по ссылке: https://drive.google.com/file/d/1n457AAgrMwd5VbT6mGZ_rws3g2wwdEfX/view?usp=sharing\n\n### Метрика качества\n\nВаш алгоритм должен выдавать пять вариантов ответа для каждого запроса.\nДля упрощения задачи метрика качества будет учитывать утилиты и флаги ответа, но не учитывать подставленные значения. Пусть $\\{ u_1, \\ldots, u_T \\}$, $\\{ f_1, \\ldots, f_T \\}$ --- список утилит и множества их флагов ответа алгоритма, $\\{v_1, \\ldots, v_T \\}$, $\\{ \\phi_1, \\ldots, \\phi_T \\}$ --- список утилит и множества их флагов эталонного ответа. Если ответы отличаются по длине, они дополняются `None` утилитой.\n\n$$ S = \\frac{1}{T} \\sum_{i=1}^{T} \\left(\\mathbb{I}[u_i = v_i]\\left( 1 + \\frac{1}{2}s(f_i, \\phi_i)\\right) - 1\\right)$$\n\n$$ s(f, \\phi) = 1 + \\frac{2 |f \\cap \\phi| - |f \\cup \\phi|}{\\max(|f|, |\\phi|)} $$\n\nМетрика учитывает, что предсказать правильную утилиту важнее чем правильный флаг. При этом порядок флагов не важен (однако, чтобы корректно","metadata":{"id":"Nr4csiUigcbl"}},{"cell_type":"markdown","source":"## Предобработка данных (2 балла)","metadata":{"id":"pXPysIwzgcbm"}},{"cell_type":"code","source":"# Скачать архив ветки nlc2cmd\n!wget https://github.com/IBM/clai/archive/refs/heads/nlc2cmd.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:35.110715Z","iopub.execute_input":"2024-12-21T19:52:35.111019Z","iopub.status.idle":"2024-12-21T19:52:42.137543Z","shell.execute_reply.started":"2024-12-21T19:52:35.110995Z","shell.execute_reply":"2024-12-21T19:52:42.136613Z"}},"outputs":[{"name":"stdout","text":"--2024-12-21 19:52:35--  https://github.com/IBM/clai/archive/refs/heads/nlc2cmd.zip\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://codeload.github.com/IBM/clai/zip/refs/heads/nlc2cmd [following]\n--2024-12-21 19:52:35--  https://codeload.github.com/IBM/clai/zip/refs/heads/nlc2cmd\nResolving codeload.github.com (codeload.github.com)... 140.82.112.9\nConnecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [application/zip]\nSaving to: ‘nlc2cmd.zip.1’\n\nnlc2cmd.zip.1           [             <=>    ] 103.21M  15.9MB/s    in 6.5s    \n\n2024-12-21 19:52:42 (15.9 MB/s) - ‘nlc2cmd.zip.1’ saved [108220962]\n\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# Разархивировать только папки utils\n!unzip nlc2cmd.zip 'clai-nlc2cmd/utils/*' -d ./\n\n# Переместить извлеченные папки в рабочую директорию\n!mv clai-nlc2cmd/utils ./utils\n\n# Проверить содержимое папок\n!ls ./utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.138871Z","iopub.execute_input":"2024-12-21T19:52:42.139135Z","iopub.status.idle":"2024-12-21T19:52:42.596161Z","shell.execute_reply.started":"2024-12-21T19:52:42.139113Z","shell.execute_reply":"2024-12-21T19:52:42.595251Z"}},"outputs":[{"name":"stdout","text":"Archive:  nlc2cmd.zip\n2ad172acbed0c1ec870cc39f47635adea39f19c0\n   creating: ./clai-nlc2cmd/utils/\n   creating: ./clai-nlc2cmd/utils/bashlint/\n  inflating: ./clai-nlc2cmd/utils/bashlint/README.md  \n  inflating: ./clai-nlc2cmd/utils/bashlint/__init__.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/bash.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/bast.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/bparser.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/butils.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/constants.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/data_tools.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/errors.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/flags.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/grammar.py  \n   creating: ./clai-nlc2cmd/utils/bashlint/grammar/\n  inflating: ./clai-nlc2cmd/utils/bashlint/grammar/extract_man.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/grammar/grammar100.txt  \n  inflating: ./clai-nlc2cmd/utils/bashlint/grammar/top100.txt  \n  inflating: ./clai-nlc2cmd/utils/bashlint/heredoc.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/lint.py  \n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/\n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/ManParserInterface.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/ManParserInterfaceTest.java  \n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/cmd/\n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/cmd/Cmd.java  \n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/\n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/Makefile  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/ParseException.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/SimpleCharStream.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/SynopParser.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/SynopParserConstants.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/SynopParserTokenManager.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/Token.java  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/TokenMgrError.java  \n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/javacc/\n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/javacc/bin/\n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/javacc/bin/javacc  \n   creating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/javacc/bin/lib/\n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/javacc/bin/lib/javacc.jar  \n  inflating: ./clai-nlc2cmd/utils/bashlint/man_parser/parser/synopsis.jj  \n  inflating: ./clai-nlc2cmd/utils/bashlint/nast.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/parsetab.py  \n extracting: ./clai-nlc2cmd/utils/bashlint/requirements.txt  \n  inflating: ./clai-nlc2cmd/utils/bashlint/rewrites.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/shutils.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/state.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/subst.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/tokenizer.py  \n  inflating: ./clai-nlc2cmd/utils/bashlint/yacc.py  \n   creating: ./clai-nlc2cmd/utils/metric/\n  inflating: ./clai-nlc2cmd/utils/metric/README.md  \n extracting: ./clai-nlc2cmd/utils/metric/__init__.py  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/README.md  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/__init__.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/bash.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/bast.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/bparser.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/butils.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/constants.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/data_tools.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/errors.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/flags.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/grammar.py  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/grammar/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/grammar/extract_man.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/grammar/grammar100.txt  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/grammar/top100.txt  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/heredoc.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/lint.py  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/ManParserInterface.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/ManParserInterfaceTest.java  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/cmd/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/cmd/Cmd.java  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/Makefile  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/ParseException.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/SimpleCharStream.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/SynopParser.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/SynopParserConstants.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/SynopParserTokenManager.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/Token.java  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/TokenMgrError.java  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/javacc/\n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/javacc/bin/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/javacc/bin/javacc  \n   creating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/javacc/bin/lib/\n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/javacc/bin/lib/javacc.jar  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/man_parser/parser/synopsis.jj  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/nast.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/parsetab.py  \n extracting: ./clai-nlc2cmd/utils/metric/bashlint/requirements.txt  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/rewrites.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/shutils.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/state.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/subst.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/tokenizer.py  \n  inflating: ./clai-nlc2cmd/utils/metric/bashlint/yacc.py  \n  inflating: ./clai-nlc2cmd/utils/metric/metric_utils.py  \n extracting: ./clai-nlc2cmd/utils/metric/requirements.txt  \nbashlint  metric  utils\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"import sys\nPATH_TO_CLAI_UTILS = '/kaggle/working/utils'\nsys.path.append(PATH_TO_CLAI_UTILS)","metadata":{"id":"WED6TGldgcbm","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.598042Z","iopub.execute_input":"2024-12-21T19:52:42.598304Z","iopub.status.idle":"2024-12-21T19:52:42.603158Z","shell.execute_reply.started":"2024-12-21T19:52:42.598282Z","shell.execute_reply":"2024-12-21T19:52:42.601924Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"import os\n\n# Путь к файлу, который нужно изменить\nfile_path = '/kaggle/working/utils/bashlint/butils.py'\n\n# Проверьте, существует ли файл\nif os.path.exists(file_path):\n    with open(file_path, 'r') as file:\n        # Читаем содержимое файла\n        content = file.read()\n\n    # Заменяем 'collections.MutableSet' на 'collections.abc.MutableSet'\n    updated_content = content.replace('collections.MutableSet', 'collections.abc.MutableSet')\n    updated_content = updated_content.replace('collections.Mapping', 'collections.abc.Mapping')\n\n    # Записываем изменения обратно в файл\n    with open(file_path, 'w') as file:\n        file.write(updated_content)\n\n    print(f\"Файл {file_path} успешно обновлен.\")\nelse:\n    print(f\"Файл {file_path} не найден.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.604893Z","iopub.execute_input":"2024-12-21T19:52:42.605242Z","iopub.status.idle":"2024-12-21T19:52:42.623189Z","shell.execute_reply.started":"2024-12-21T19:52:42.605215Z","shell.execute_reply":"2024-12-21T19:52:42.622166Z"}},"outputs":[{"name":"stdout","text":"Файл /kaggle/working/utils/bashlint/butils.py успешно обновлен.\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom bashlint.data_tools import bash_parser, pretty_print, cmd2template\nfrom metric.metric_utils import compute_metric\nfrom functools import partial\n\nfrom collections import Counter\nimport sentencepiece as spm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport nltk\n\nimport sys\nimport os\n\nimport torch.nn.functional as F\nfrom collections import defaultdict","metadata":{"id":"KuOn0E2Ggcbn","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.624273Z","iopub.execute_input":"2024-12-21T19:52:42.624588Z","iopub.status.idle":"2024-12-21T19:52:42.649338Z","shell.execute_reply.started":"2024-12-21T19:52:42.624566Z","shell.execute_reply":"2024-12-21T19:52:42.648637Z"}},"outputs":[],"execution_count":86},{"cell_type":"markdown","source":"Считаем данные. В столбце `invocation` находится текстовый запрос, в столбце `cmd` находится релевантная команда.","metadata":{"id":"SPDxvJ8jgcbn"}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/text2bash-data/train.csv')\ntrain_data.head()","metadata":{"id":"P_ixsl2fgcbo","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.650638Z","iopub.execute_input":"2024-12-21T19:52:42.650985Z","iopub.status.idle":"2024-12-21T19:52:42.708876Z","shell.execute_reply.started":"2024-12-21T19:52:42.650931Z","shell.execute_reply":"2024-12-21T19:52:42.707981Z"}},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"                                          invocation  \\\n0  copy loadable kernel module \"mymodule.ko\" to t...   \n1  display all lines containing \"ip_mroute\" in th...   \n2  display current running kernel's compile-time ...   \n3  find all loadable modules for current kernel, ...   \n4  look for any instance of \"highmem\" in the curr...   \n\n                                                 cmd  \n0  sudo cp mymodule.ko /lib/modules/$(uname -r)/k...  \n1       cat /boot/config-`uname -r` | grep IP_MROUTE  \n2                        cat /boot/config-`uname -r`  \n3       find /lib/modules/`uname -r` -regex .*perf.*  \n4             grep “HIGHMEM” /boot/config-`uname -r`  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>invocation</th>\n      <th>cmd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>copy loadable kernel module \"mymodule.ko\" to t...</td>\n      <td>sudo cp mymodule.ko /lib/modules/$(uname -r)/k...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>display all lines containing \"ip_mroute\" in th...</td>\n      <td>cat /boot/config-`uname -r` | grep IP_MROUTE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>display current running kernel's compile-time ...</td>\n      <td>cat /boot/config-`uname -r`</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>find all loadable modules for current kernel, ...</td>\n      <td>find /lib/modules/`uname -r` -regex .*perf.*</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>look for any instance of \"highmem\" in the curr...</td>\n      <td>grep “HIGHMEM” /boot/config-`uname -r`</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":87},{"cell_type":"markdown","source":"В тестовых данных столбец `origin` отвечает за источник данных, значения `handrafted` соответствуют парам, составленными людьми, а `mined` парам, собранным автоматически.","metadata":{"id":"aTYR1skvgcbo"}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/text2bash-data/test_data.csv')\ntest_data.head()","metadata":{"id":"WyIuvXUjgcbp","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.709740Z","iopub.execute_input":"2024-12-21T19:52:42.710021Z","iopub.status.idle":"2024-12-21T19:52:42.722606Z","shell.execute_reply.started":"2024-12-21T19:52:42.709991Z","shell.execute_reply":"2024-12-21T19:52:42.721838Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"                                          invocation  \\\n0  create ssh connection to specified ip from spe...   \n1  search for commands containing string \"zeppeli...   \n2  search for location of specified file or appli...   \n3                    grant all rights to root folder   \n4     search in running processes for specified name   \n\n                        cmd       origin  \n0  ssh user123@176.0.13.154  handcrafted  \n1   history | grep zeppelin  handcrafted  \n2           whereis python3  handcrafted  \n3       sudo chmod 777 -R /  handcrafted  \n4       ps -aux | grep zepp  handcrafted  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>invocation</th>\n      <th>cmd</th>\n      <th>origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>create ssh connection to specified ip from spe...</td>\n      <td>ssh user123@176.0.13.154</td>\n      <td>handcrafted</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>search for commands containing string \"zeppeli...</td>\n      <td>history | grep zeppelin</td>\n      <td>handcrafted</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>search for location of specified file or appli...</td>\n      <td>whereis python3</td>\n      <td>handcrafted</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>grant all rights to root folder</td>\n      <td>sudo chmod 777 -R /</td>\n      <td>handcrafted</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>search in running processes for specified name</td>\n      <td>ps -aux | grep zepp</td>\n      <td>handcrafted</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":88},{"cell_type":"markdown","source":"**Задание**. Проведите предобработку текста. Рекомендуется:\n* перевести всё в нижний регистр\n* удалить стоп-слова (специфичные для выборки)\n* провести стемминг токенов\n* удалить все символы кроме латинских букв","metadata":{"id":"rdYgRqVRgcbp"}},{"cell_type":"code","source":"nltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    tokens = text.split()\n    tokens = [token for token in tokens if token not in stop_words]\n    tokens = [stemmer.stem(token) for token in tokens]\n    return ' '.join(tokens)","metadata":{"id":"lEGi7vshgcbp","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.724324Z","iopub.execute_input":"2024-12-21T19:52:42.724521Z","iopub.status.idle":"2024-12-21T19:52:42.792343Z","shell.execute_reply.started":"2024-12-21T19:52:42.724504Z","shell.execute_reply":"2024-12-21T19:52:42.791629Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"train_data['text_cleaned'] = train_data['invocation'].apply(clean_text)\ntest_data['text_cleaned'] = test_data['invocation'].apply(clean_text)","metadata":{"id":"zJgPZssQgcbp","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:42.793301Z","iopub.execute_input":"2024-12-21T19:52:42.793579Z","iopub.status.idle":"2024-12-21T19:52:44.231324Z","shell.execute_reply.started":"2024-12-21T19:52:42.793550Z","shell.execute_reply":"2024-12-21T19:52:44.230223Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"Для обработки кода воспользуемся функцией `cmd2template`:","metadata":{"id":"-4vu9Sc4gcbq"}},{"cell_type":"code","source":"train_data['cmd_cleaned'] = train_data['cmd'].apply(partial(cmd2template, loose_constraints=True))\ntest_data['cmd_cleaned'] = test_data['cmd'].apply(partial(cmd2template, loose_constraints=True))","metadata":{"id":"-gAZL7M7gcbq","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:52:44.232301Z","iopub.execute_input":"2024-12-21T19:52:44.232629Z","iopub.status.idle":"2024-12-21T19:53:10.335849Z","shell.execute_reply.started":"2024-12-21T19:52:44.232584Z","shell.execute_reply":"2024-12-21T19:53:10.335163Z"}},"outputs":[],"execution_count":91},{"cell_type":"markdown","source":"Разделим данные на обучение и валидацию. Т.к. данных очень мало, то для валидационной выборки выделим только 100 примеров.","metadata":{"id":"j09aHCUDgcbq"}},{"cell_type":"code","source":"valid_data = train_data.iloc[-100:]\ntrain_data = train_data.iloc[:-100]","metadata":{"id":"jH3FdRjYgcbq","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.336692Z","iopub.execute_input":"2024-12-21T19:53:10.336996Z","iopub.status.idle":"2024-12-21T19:53:10.341113Z","shell.execute_reply.started":"2024-12-21T19:53:10.336972Z","shell.execute_reply":"2024-12-21T19:53:10.340181Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"**Задание**. Стандартный формат входных данных для трансформеров — BPE токены. Воспользуйтесь библиотекой sentencepiece для обучения токенайзеров для текста и кода. Используйте небольшое число токенов.","metadata":{"id":"bFCd9selgcbq"}},{"cell_type":"code","source":"# Обучение токенизатора для текста\ntext_spm_path = 'text_tokenizer'\nwith open('text_train.txt', 'w') as f:\n    f.write('\\n'.join(train_data['text_cleaned'].tolist()))\n\nspm.SentencePieceTrainer.train(\n    f'--input=text_train.txt --model_prefix={text_spm_path} --vocab_size=1000 --model_type=bpe --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3'\n)\ntext_tokenizer = spm.SentencePieceProcessor(model_file=f'{text_spm_path}.model')\n\n# Обучение токенизатора для кода\ncmd_spm_path = 'cmd_tokenizer'\nwith open('cmd_train.txt', 'w') as f:\n    f.write('\\n'.join(train_data['cmd_cleaned'].tolist()))\n\nspm.SentencePieceTrainer.train(\n    f'--input=cmd_train.txt --model_prefix={cmd_spm_path} --vocab_size=500 --model_type=bpe --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3'\n)\ncmd_tokenizer = spm.SentencePieceProcessor(model_file=f'{cmd_spm_path}.model')","metadata":{"id":"mWcmAe14gcbq","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.343279Z","iopub.execute_input":"2024-12-21T19:53:10.343579Z","iopub.status.idle":"2024-12-21T19:53:10.577412Z","shell.execute_reply.started":"2024-12-21T19:53:10.343549Z","shell.execute_reply":"2024-12-21T19:53:10.576681Z"}},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":"**Задание**. Задайте датасеты и лоадеры для ваших данных. Каждая последовательность должна начинаться с BOS токена и заканчиваться EOS токеном. Рекомендуется ограничить длину входных и выходных последовательностей!","metadata":{"id":"k-FuiyWkgcbr"}},{"cell_type":"code","source":"PAD_ID = 0\nBOS_ID = 1\nEOS_ID = 2\n\n\nMAX_TEXT_LENGTH = 256\nMAX_CODE_LENGTH = 40\n\nBATCH_SIZE = 64","metadata":{"id":"mxu5Vp7ogcbr","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.578683Z","iopub.execute_input":"2024-12-21T19:53:10.578980Z","iopub.status.idle":"2024-12-21T19:53:10.582439Z","shell.execute_reply.started":"2024-12-21T19:53:10.578957Z","shell.execute_reply":"2024-12-21T19:53:10.581606Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"class TextToBashDataset(Dataset):\n    def __init__(self, dataframe, text_tokenizer, cmd_tokenizer, max_text_length, max_code_length):\n        self.data = dataframe\n        self.text_tokenizer = text_tokenizer\n        self.cmd_tokenizer = cmd_tokenizer\n        self.max_text_length = max_text_length\n        self.max_code_length = max_code_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data['text_cleaned'].iloc[idx]\n        code = self.data['cmd_cleaned'].iloc[idx]\n\n        text_tokens = self.text_tokenizer.encode(text)\n        code_tokens = self.cmd_tokenizer.encode(code)\n\n        text_tokens = text_tokens[:self.max_text_length]\n        code_tokens = code_tokens[:self.max_code_length - 1]  # Reserve space for EOS\n\n        text_tokens = [BOS_ID] + text_tokens + [EOS_ID]\n        code_tokens = [BOS_ID] + code_tokens + [EOS_ID]\n\n        text_padding_len = self.max_text_length + 2 - len(text_tokens)\n        code_padding_len = self.max_code_length + 1 - len(code_tokens) # Correction here\n\n        text_tokens += [PAD_ID] * text_padding_len\n        code_tokens += [PAD_ID] * code_padding_len\n\n        return {\n            'input_ids': torch.tensor(text_tokens),\n            'attention_mask': torch.tensor([1 if token != PAD_ID else 0 for token in text_tokens]),\n            'decoder_input_ids': torch.tensor(code_tokens[:-1]), # Shifted for teacher forcing\n            'decoder_attention_mask': torch.tensor([1 if token != PAD_ID else 0 for token in code_tokens[:-1]]),\n            'labels': torch.tensor(code_tokens[1:]) # Target for prediction\n        }","metadata":{"id":"s071TM0Rgcbr","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.583282Z","iopub.execute_input":"2024-12-21T19:53:10.583511Z","iopub.status.idle":"2024-12-21T19:53:10.598299Z","shell.execute_reply.started":"2024-12-21T19:53:10.583492Z","shell.execute_reply":"2024-12-21T19:53:10.597535Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"train_ds = TextToBashDataset(train_data, text_tokenizer, cmd_tokenizer, MAX_TEXT_LENGTH, MAX_CODE_LENGTH)\nvalid_ds = TextToBashDataset(valid_data, text_tokenizer, cmd_tokenizer, MAX_TEXT_LENGTH, MAX_CODE_LENGTH)","metadata":{"id":"ALHK0KNEgcbr","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.599118Z","iopub.execute_input":"2024-12-21T19:53:10.599404Z","iopub.status.idle":"2024-12-21T19:53:10.619500Z","shell.execute_reply.started":"2024-12-21T19:53:10.599368Z","shell.execute_reply":"2024-12-21T19:53:10.618885Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"loaders = {\n    'train': DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True),\n    'valid': DataLoader(valid_ds, batch_size=BATCH_SIZE),\n}","metadata":{"id":"14slMAPtgcbr","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.620209Z","iopub.execute_input":"2024-12-21T19:53:10.620391Z","iopub.status.idle":"2024-12-21T19:53:10.637817Z","shell.execute_reply.started":"2024-12-21T19:53:10.620374Z","shell.execute_reply":"2024-12-21T19:53:10.636985Z"}},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":"## Обучение бейзлайна (2 балла)","metadata":{"id":"Sgpe-nN0gcbs"}},{"cell_type":"code","source":"from transformers import BertConfig, BertModel, EncoderDecoderConfig, EncoderDecoderModel","metadata":{"id":"0Tv-uPk-gcbs","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.638943Z","iopub.execute_input":"2024-12-21T19:53:10.639211Z","iopub.status.idle":"2024-12-21T19:53:10.651794Z","shell.execute_reply.started":"2024-12-21T19:53:10.639192Z","shell.execute_reply":"2024-12-21T19:53:10.651156Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"**Задание.** Реализуйте модель encoder-decoder ниже. В качестве моделей энкодера и декодера рекомендуется использовать BertModel из библиотеки transformers, заданную через BertConfig. В случае декодера необходимо выставить параметры is_decoder=True и add_cross_attention=True. В качестве модели, <<сцепляющей>> энкодер и декодер, в одну архитектуру рекомендуется использовать EncoderDecoderModel.\n\n**Обратите внимание!** EncoderDecoderModel поддерживает использование кэшированных результатов при последовательной генерации. Это пригодится при реализации beam-search ниже.\n\nДля того, чтобы удобнее задавать модели, рекомендуется реализовать задание модели через конфиг. Ниже представлены базовые параметры, при которых модель должна работать быстро и с приемлемым качеством.","metadata":{"id":"HxSJa2-jgcbs"}},{"cell_type":"code","source":"text_model_config = {\n    'vocab': text_tokenizer.vocab_size(),\n    'hidden_size': 256,\n    'num_layers': 2,\n    'num_attention_heads': 8,\n    'intermediate_size': 256 * 4,\n    'hidden_dropout_prob': 0.1,\n    'pad_id': PAD_ID,\n}\n\ncmd_model_config = {\n    'vocab': cmd_tokenizer.vocab_size(),\n    'hidden_size': 256,\n    'num_layers': 2,\n    'num_attention_heads': 8,\n    'intermediate_size': 256 * 4,\n    'hidden_dropout_prob': 0.1,\n    'pad_id': PAD_ID,\n}","metadata":{"id":"1meXHP5wgcbs","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.652624Z","iopub.execute_input":"2024-12-21T19:53:10.652842Z","iopub.status.idle":"2024-12-21T19:53:10.669807Z","shell.execute_reply.started":"2024-12-21T19:53:10.652793Z","shell.execute_reply":"2024-12-21T19:53:10.669025Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"class TextToBashModel(nn.Module):\n    def __init__(self, text_config, cmd_config):\n        super().__init__()\n        encoder_config = BertConfig(**text_config)\n        decoder_config = BertConfig(**cmd_config, is_decoder=True, add_cross_attention=True)\n        config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config, decoder_config)\n        self.model = EncoderDecoderModel(config=config)\n        self.model.config.decoder_start_token_id = BOS_ID\n\n    def forward(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask):\n        outputs = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n        )\n        return outputs.logits","metadata":{"id":"zg0GGP1Lgcbs","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.672329Z","iopub.execute_input":"2024-12-21T19:53:10.672526Z","iopub.status.idle":"2024-12-21T19:53:10.684896Z","shell.execute_reply.started":"2024-12-21T19:53:10.672509Z","shell.execute_reply":"2024-12-21T19:53:10.684276Z"}},"outputs":[],"execution_count":100},{"cell_type":"markdown","source":"**Задание**. Обучите вашу модель ниже.\n\nРекомендуется:\n* в качестве лосса использовать стандартную кросс-энтропию, не забывайте игнорировать PAD токены\n* использовать Adam для оптимизации\n* не использовать scheduler для бейзлайна (модель легко переобучается с ним)\n* использовать early stopping по валидационному лоссу","metadata":{"id":"Wz5BSTAIgcbs"}},{"cell_type":"code","source":"from torch.optim import AdamW\nfrom tqdm import tqdm\n\n# Инициализация \nmodel = TextToBashModel(text_model_config, cmd_model_config)\nloss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\noptimizer = AdamW(model.parameters(), lr=1e-4)\n\n# Параметры обучения\nnum_epochs = 10\npatience = 3\nbest_valid_loss = float('inf')\nepochs_no_improve = 0\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Цикл обучения\nfor epoch in tqdm(range(num_epochs)):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()\n    train_loss = 0.0\n    for batch in loaders['train']:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        decoder_input_ids = batch['decoder_input_ids'].to(device)\n        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask\n        )\n        loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    avg_train_loss = train_loss / len(loaders['train'])\n    print(f\"Train Loss: {avg_train_loss:.4f}\")\n\n    model.eval()\n    valid_loss = 0.0\n    with torch.no_grad():\n        for batch in loaders['valid']:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            decoder_input_ids = batch['decoder_input_ids'].to(device)\n            decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                decoder_input_ids=decoder_input_ids,\n                decoder_attention_mask=decoder_attention_mask\n            )\n            loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n            valid_loss += loss.item()\n\n    avg_valid_loss = valid_loss / len(loaders['valid'])\n    print(f\"Valid Loss: {avg_valid_loss:.4f}\")\n\n    # Early stopping\n    if avg_valid_loss < best_valid_loss:\n        best_valid_loss = avg_valid_loss\n        epochs_no_improve = 0\n        torch.save(model.state_dict(), 'best_model.pth')  # Сохранение лучшей модели\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve == patience:\n            print(\"Early stopping triggered\")\n            break\n\nprint(\"Finished Training\")","metadata":{"id":"go3vQCyagcbs","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:53:10.686019Z","iopub.execute_input":"2024-12-21T19:53:10.686257Z","iopub.status.idle":"2024-12-21T20:12:30.729882Z","shell.execute_reply.started":"2024-12-21T19:53:10.686237Z","shell.execute_reply":"2024-12-21T20:12:30.729015Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 5.8689\nValid Loss: 3.8312\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [01:56<17:28, 116.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\nTrain Loss: 2.6619\nValid Loss: 2.8474\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [03:52<15:28, 116.12s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10\nTrain Loss: 1.9638\nValid Loss: 2.3762\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [05:48<13:31, 115.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10\nTrain Loss: 1.6077\nValid Loss: 2.0866\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [07:43<11:35, 115.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10\nTrain Loss: 1.3808\nValid Loss: 1.9097\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [09:39<09:39, 115.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10\nTrain Loss: 1.2209\nValid Loss: 1.7359\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [11:35<07:43, 115.82s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10\nTrain Loss: 1.1052\nValid Loss: 1.6235\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [13:31<05:47, 115.86s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10\nTrain Loss: 1.0093\nValid Loss: 1.5450\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [15:27<03:51, 115.89s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10\nTrain Loss: 0.9292\nValid Loss: 1.4878\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [17:23<01:55, 115.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10\nTrain Loss: 0.8621\nValid Loss: 1.4635\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [19:19<00:00, 115.92s/it]","output_type":"stream"},{"name":"stdout","text":"Finished Training\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":101},{"cell_type":"markdown","source":"## Генерация команд (2 балла)\n\n**Задание**. Реализуйте алгоритм beam-search в классе BeamSearchGenerator ниже. Ваша реализация должна поддерживать задание температуры софтмакса. Выходы модели, полученные на предыдущих итерациях, необходимо кэшировать для повышения скорости алгоритма. Вместо подсчёта произведения любых вероятностей необходимо считать сумму их логарифмов.\n\nАлгоритм должен возвращать список пар из получившихся выходных последовательностей и логарифмов их вероятностей.","metadata":{"id":"IAD20fkPgcbs"}},{"cell_type":"code","source":"class BeamSearchGenerator:\n    def __init__(\n            self, pad_id, eos_id, bos_id,\n            max_length=20, beam_width=5, temperature=1,\n            device='cuda'\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        pad_id : int\n        eos_id : int\n        bos_id : int\n        max_length : int\n            Maximum length of output sequence\n        beam_width : int\n            Width of the beam\n        temperature : float\n            Softmax temperature\n        device : torch.device\n            Your model device\n        \"\"\"\n        self.pad_id = pad_id\n        self.eos_id = eos_id\n        self.bos_id = bos_id\n        self.max_length = max_length\n        self.beam_width = beam_width\n        self.temperature = temperature\n        self.device = device\n\n    def get_result(self, model, input_text_tokens):\n        \"\"\"\n        Parameters\n        ----------\n        model : TextToBashModel\n        input_text_tokens : torch.tensor\n            One object input tensor\n        Returns\n        -------\n        List of tuples: [(sequence, log_prob), ...]\n        \"\"\"\n        # Перемещаем входные токены на устройство и добавляем батч-размер 1\n        input_text_tokens = input_text_tokens.unsqueeze(0).to(self.device)  # Shape: [1, seq_len]\n        attention_mask = (input_text_tokens != self.pad_id).long()\n\n        # Получаем выходы энкодера и кэшируем их\n        encoder_outputs = model.model.encoder(\n            input_ids=input_text_tokens,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n\n        # Инициализируем луч с начальной последовательностью [BOS_ID] и лог вероятностью 0\n        beams = [([self.bos_id], 0.0)]\n        # Список завершенных последовательностей\n        completed_beams = []\n\n        for _ in range(self.max_length):\n            # Собираем все текущие активные последовательности\n            active_beams = [beam for beam in beams if beam[0][-1] != self.eos_id]\n            # Если нет активных последовательностей, прекращаем генерацию\n            if len(active_beams) == 0:\n                break\n\n            # Подготовка декодерских входов: батч всех активных последовательностей\n            current_batch_size = len(active_beams)\n            decoder_input_ids = torch.tensor([beam[0] for beam in active_beams], device=self.device)  # Shape: [batch, seq_len]\n            decoder_attention_mask = (decoder_input_ids != self.pad_id).long()\n\n            # Получаем выходы декодера\n            decoder_outputs = model.model.decoder(\n                input_ids=decoder_input_ids,\n                attention_mask=decoder_attention_mask,\n                encoder_hidden_states=encoder_outputs.last_hidden_state,\n                encoder_attention_mask=attention_mask,\n                return_dict=True\n            )\n\n            # Получаем логиты для последнего токена в каждой последовательности\n            logits = decoder_outputs.logits[:, -1, :]  # Shape: [batch, vocab_size]\n            logits = logits / self.temperature\n            log_probs = F.log_softmax(logits, dim=-1)  # Shape: [batch, vocab_size]\n\n            # Выбираем топ beam_width вероятностей и их индексы для каждой последовательности\n            top_log_probs, top_indices = torch.topk(log_probs, self.beam_width, dim=-1)  # Each of shape [batch, beam_width]\n\n            # Расширяем текущие лучи с топ кандидатов\n            all_candidates = []\n            for i in range(current_batch_size):\n                seq, seq_log_prob = active_beams[i]\n                for j in range(self.beam_width):\n                    token = top_indices[i, j].item()\n                    token_log_prob = top_log_probs[i, j].item()\n                    new_seq = seq + [token]\n                    new_log_prob = seq_log_prob + token_log_prob\n                    if token == self.eos_id:\n                        completed_beams.append((new_seq, new_log_prob))\n                    else:\n                        all_candidates.append((new_seq, new_log_prob))\n\n            # Если нет кандидатов, прекращаем генерацию\n            if len(all_candidates) == 0:\n                break\n\n            # Сортируем все кандидаты по log_prob и выбираем top beam_width\n            all_candidates = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n            beams = all_candidates[:self.beam_width]\n\n        # Добавляем оставшиеся лучи, которые могли быть завершены EOS на последнем шаге\n        completed_beams.extend(beams)\n\n        # Сортируем все завершенные лучи и выбираем top beam_width\n        completed_beams = sorted(completed_beams, key=lambda x: x[1], reverse=True)\n        return completed_beams[:self.beam_width]","metadata":{"id":"7ouLaM_Rgcbt","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:14:09.802065Z","iopub.execute_input":"2024-12-21T20:14:09.802421Z","iopub.status.idle":"2024-12-21T20:14:09.813002Z","shell.execute_reply.started":"2024-12-21T20:14:09.802395Z","shell.execute_reply":"2024-12-21T20:14:09.812029Z"}},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":"Протестируйте на нескольких примерах работу вашего алгоритма. Если всё реализовано правильно, то как минимум на трёх примерах из 5 всё должно работать правильно.","metadata":{"id":"0IeMMcrtgcbt"}},{"cell_type":"code","source":"beam_search_engine = BeamSearchGenerator(\n    pad_id=PAD_ID, eos_id=EOS_ID, bos_id=BOS_ID,\n    max_length=MAX_CODE_LENGTH, beam_width=10,\n    temperature=0.8, device='cuda',\n)","metadata":{"id":"PGvmHpOBgcbt","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:14:10.510081Z","iopub.execute_input":"2024-12-21T20:14:10.510430Z","iopub.status.idle":"2024-12-21T20:14:10.514296Z","shell.execute_reply.started":"2024-12-21T20:14:10.510402Z","shell.execute_reply":"2024-12-21T20:14:10.513482Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"with torch.no_grad():\n    for i in range(5):\n        print()\n        print('text:', valid_data.invocation.iloc[i])\n        print('true:', valid_data.cmd.iloc[i])\n        print('true cleaned:', valid_data.cmd_cleaned.iloc[i])\n\n        input_text = valid_data.text_cleaned.iloc[i]\n        input_tokens = torch.tensor([BOS_ID] + text_tokenizer.encode(input_text) + [EOS_ID]).to(device)\n        pred = beam_search_engine.get_result(model, input_tokens)\n\n        scores = []\n        for tokens, proba in pred:\n            # Прямое декодирование списка токенов\n            pred_cmd = cmd_tokenizer.decode(tokens)\n            score = compute_metric(pred_cmd, 1, valid_data.cmd.iloc[i])\n            scores.append(score)\n            print(pred_cmd, proba)\n        if scores:\n            print(f\"Best score: {max(scores)}\")\n        else:\n            print(\"No predictions generated.\")","metadata":{"id":"tJqMLfWjgcbt","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:14:59.279768Z","iopub.execute_input":"2024-12-21T20:14:59.280064Z","iopub.status.idle":"2024-12-21T20:15:03.770672Z","shell.execute_reply.started":"2024-12-21T20:14:59.280042Z","shell.execute_reply":"2024-12-21T20:15:03.769720Z"}},"outputs":[{"name":"stdout","text":"\ntext: searches through the root filesystem (\"/\") for the file named chapter1, and prints the location\ntrue: find / -name Chapter1 -type f -print\ntrue cleaned: find Path -name Regex -type f -print\nfind Path -name Regex -print -1.4612334616249427\nfind Path -name Regex -type f -1.8078021722612903\nfind Path -name Regex -exec echo {} \\; -2.8884599677985534\nfind Path -name Regex -type f -print -2.9969136434374377\nfind Path -name Regex -3.0307849295204505\nfind Path -name Regex -print0 -3.5620478339260444\nfind Path -name Regex -type f -print0 -3.5942550020990893\nfind Path -type f -name Regex -print0 -4.138198224420194\nfind Path -name Regex -printf \"%f\\n\" -4.789454309619032\nfind Path -name Regex -name Regex -4.8851425586035475\nBest score: 1.0\n\ntext: searches through the root filesystem (\"/\") for the file named chapter1.\ntrue: find / -name Chapter1 -type f\ntrue cleaned: find Path -name Regex -type f\nfind Path -name Regex -type f -1.109224942571018\nfind Path -name Regex -2.074280857166741\nfind Path -name Regex -type f -print -2.2548587890923955\nfind Path -name Regex -type f -name Regex -3.0928955170093104\nfind Path -name Regex -print -3.1457439950318076\nfind Path -name Regex -name Regex -3.404191200796049\nfind Path -type f -name Regex -3.6547829132759944\nfind Path -type f -name Regex -print -3.9759447794640437\nfind Path -name Regex -name Regex -type f -4.4121589830028825\nfind Path -name Regex -type f -name Regex -print -4.708607194828801\nBest score: 1.0\n\ntext: searches through the root filesystem (\"/\") for the file named chapter1.\ntrue: find / -name Chapter1 -type f -print\ntrue cleaned: find Path -name Regex -type f -print\nfind Path -name Regex -type f -1.109224942571018\nfind Path -name Regex -2.074280857166741\nfind Path -name Regex -type f -print -2.2548587890923955\nfind Path -name Regex -type f -name Regex -3.0928955170093104\nfind Path -name Regex -print -3.1457439950318076\nfind Path -name Regex -name Regex -3.404191200796049\nfind Path -type f -name Regex -3.6547829132759944\nfind Path -type f -name Regex -print -3.9759447794640437\nfind Path -name Regex -name Regex -type f -4.4121589830028825\nfind Path -name Regex -type f -name Regex -print -4.708607194828801\nBest score: 1.0\n\ntext: searching for all files with the extension mp3\ntrue: find / -name *.mp3\ntrue cleaned: find Path -name Regex\nfind Path -name Regex -0.7313802550197579\nfind Path -name Regex -print -1.8388621966005303\nfind Path -type f -name Regex -2.1782961494172923\nfind Path -iname Regex -3.412448030547239\nfind Path -name Regex -type f -3.486936807690654\nfind Path -name Regex -or -name Regex -3.6310968039324507\nfind Path -type f -name Regex -print -4.2364878809894435\nfind Path -name Regex -exec grep Regex {} \\; -4.581578946730588\nfind Path -name Regex -type f -print -4.9838033766136505\nfind Path -type f -iname Regex -5.050254924863111\nBest score: 1.0\n\ntext: set myvariable to the value of variable_name\ntrue: myVariable=$(env  | grep VARIABLE_NAME | grep -oe '[^=]*$');\ntrue cleaned: env | grep Regex | grep -o -e Regex\ncat File | grep -v Regex -3.2470600306987762\nsed -e Program -3.69068505987525\ncat File | sed -e Program -3.713354179635644\ncat File | sed Program -3.8133318200707436\ncat File | grep Regex -3.8247100487351418\nsed -e Program Program -4.209069814532995\necho Regex | sed -e Program -4.251426199451089\nawk Program Program -4.6836461164057255\necho Regex | sed Program -4.7355857491493225\nsed Program File -4.810554146766663\nBest score: -0.3333333333333333\n","output_type":"stream"}],"execution_count":108},{"cell_type":"markdown","source":"**Задание**. Дополните функцию для подсчёта качества. Посчитайте качество вашей модели на валидационном и тестовых датасетов.","metadata":{"id":"wjSlUHqbgcbt"}},{"cell_type":"code","source":"def compute_all_scores(model, df, beam_engine):\n    all_scores = []\n    print(\"Количество итераций\", df.text_cleaned.values.shape)\n    for i, (text, target_cmd) in tqdm(enumerate(zip(df.text_cleaned.values, df.cmd.values))):\n        input_tokens = torch.tensor([BOS_ID] + text_tokenizer.encode(text) + [EOS_ID]).to(device)\n        predictions = beam_engine.get_result(model, input_tokens)\n\n        # Get only 5 top results\n        predictions = predictions[:5]\n        object_scores = []\n        for output_tokens, proba in predictions:\n            output_cmd = cmd_tokenizer.decode(output_tokens)\n            score = compute_metric(output_cmd, 1, target_cmd)\n            object_scores.append(score)\n\n        if object_scores:\n            all_scores.append(max(object_scores))\n        else:\n            all_scores.append(0.0) # Assign a score of 0 if no predictions\n\n    return all_scores","metadata":{"id":"sJiW5_5dgcbt","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:16:35.148274Z","iopub.execute_input":"2024-12-21T20:16:35.148591Z","iopub.status.idle":"2024-12-21T20:16:35.154203Z","shell.execute_reply.started":"2024-12-21T20:16:35.148563Z","shell.execute_reply":"2024-12-21T20:16:35.153319Z"}},"outputs":[],"execution_count":111},{"cell_type":"markdown","source":"Ваша цель при помощи подбора параметров модели и генерации получить средний скор на валидации >= 0.2, скор `handcrafted` части теста >= 0.1. На `mined` части датасета скор может быть низкий, т.к. некоторых команд из датасета нет в обучении.\n\n**Обратите внимание.** Так как датасет для обучения не очень большой, а данные достаточно нестабильные, подбор параметров может очень сильно влиять на модель. Некоторые полезные советы:\n* Отслеживайте качество модели после каждой эпохи, не забывайте про early stopping\n* Вы можете сразу приступить к следующей части. Побитие скора в этой части задания при помощи трюков из бонусной части считается валидным.","metadata":{"id":"Jnj7FQ-Jgcbt"}},{"cell_type":"code","source":"# Calculate scores on validation set\nvalid_scores = compute_all_scores(model, valid_data, beam_search_engine)\nprint(f\"Average validation score: {np.mean(valid_scores)}\")\n\n# Calculate scores on test set\ntest_scores = compute_all_scores(model, test_data, beam_search_engine)\nprint(f\"Average test score: {np.mean(test_scores)}\")\n\n# Calculate scores on handcrafted test data\nhandcrafted_test_data = test_data[test_data['origin'] == 'handcrafted']\nhandcrafted_scores = compute_all_scores(model, handcrafted_test_data, beam_search_engine)\nprint(f\"Average handcrafted test score: {np.mean(handcrafted_scores)}\")\n\n# Calculate scores on mined test data\nmined_test_data = test_data[test_data['origin'] == 'mined']\nmined_scores = compute_all_scores(model, mined_test_data, beam_search_engine)\nprint(f\"Average mined test score: {np.mean(mined_scores)}\")","metadata":{"id":"4lumgYyKgcbx","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:16:37.022842Z","iopub.execute_input":"2024-12-21T20:16:37.023205Z","iopub.status.idle":"2024-12-21T20:42:45.826808Z","shell.execute_reply.started":"2024-12-21T20:16:37.023167Z","shell.execute_reply":"2024-12-21T20:42:45.825310Z"}},"outputs":[{"name":"stdout","text":"Количество итераций (100,)\n","output_type":"stream"},{"name":"stderr","text":"100it [01:41,  1.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average validation score: 0.22001388888888887\nКоличество итераций (721,)\n","output_type":"stream"},{"name":"stderr","text":"721it [12:13,  1.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average test score: -0.19282398234374654\nКоличество итераций (129,)\n","output_type":"stream"},{"name":"stderr","text":"129it [02:11,  1.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average handcrafted test score: 0.14664082687338503\nКоличество итераций (592,)\n","output_type":"stream"},{"name":"stderr","text":"592it [10:01,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"Average mined test score: -0.2667951992170742\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":112},{"cell_type":"markdown","source":"## Улучшение модели (4 балла)\n\nВы реализовали бейзлайн, пришло время улучшить качество модели. Т.к. это последнее задание, мы не будем предлагать конкретные шаги, а только дадим несколько советов.\n\n1. Большой источник информации о работе командной строке — её документация, man. Один из способов улучшения модели - использование мана для генерации новых примеров. Структурированный ман можно найти по ссылке https://github.com/IBM/clai/blob/nlc2cmd/docs/manpage-data.md.\n2. Ещё один способ улучшить модель, разделить предсказание утилит и флагов. Т.к. задача предсказания утилит более важная, вы можете натренировать модель, которая предсказывает последовательность утилит, а затем к каждой утилите генерировать флаги.\n3. Можно аугментировать данные, чтобы увеличить выборку.\n4. Можно в качество входа подавать не только текстовый запрос, но и описание из мана. Т.к. всё описание достаточно большое, нужно сделать дополнительную модель, которая будет выбирать команды, для которых нужно вытащить описание.\n5. Найти дополнительные данные, улучшающие обучение\n6. Как всегда можно просто сделать больше слоёв, увеличить размер скрытого слоя и т.д.","metadata":{"id":"7kE7ysJNgcbx"}},{"cell_type":"markdown","source":"От вас ожидается скор на валидации >= 0.25, `mined` >= 0, `handrafted` >= 0.15.","metadata":{"id":"rPWM_wz9gcbx"}},{"cell_type":"code","source":"","metadata":{"id":"jTqXP4-Zgcbx"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Бонусные баллы (до 3 баллов)\n\nПри существенном улучшении качества будут назначаться бонусные баллы. На тестовых датасетах реально выбить качество >= 0.3 на каждом, но усилий потребуется немало...","metadata":{"id":"DVm9eOKzgcbx"}}]}